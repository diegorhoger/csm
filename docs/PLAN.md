# Stoic Mentor â†’ Council Implementation Plan

## Project Overview
Council is an emotionally intelligent, voice-first AI mentor designed to guide users through an inner journey of growth using real-time emotion recognition, stoic philosophy, and advanced conversational intelligence. The application enables natural, human-like conversations with different mentors who adapt to the user's emotional state.

## Core Components (Completed)
- âœ… React/TypeScript project setup with Vite
- âœ… Component architecture and state management
- âœ… Basic UI/UX implementation
- âœ… Audio recording and playback system
- âœ… WebSocket-based Voice Activity Detection (VAD)
- âœ… OpenAI integration for transcription and responses
- âœ… Initial text-to-speech implementation

## Priority 0: Backend Architectural Refactoring (COMPLETED)
- âœ… Move OpenAI integration from frontend to backend
- âœ… Create dedicated mentor conversation API endpoints
- âœ… Implement conversation session management on server
- âœ… Secure API keys and implement usage monitoring
- âœ… Set up streaming response mechanism for real-time feedback

## Priority 1: WebSocket VAD Integration (COMPLETED)
- âœ… Fix WebSocket connection issues with proper CORS configuration
- âœ… Implement proper error handling for WebSocket connections
- âœ… Create diagnostic and testing tools for WebSocket VAD
- âœ… Add connection health checks and automatic recovery
- âœ… Optimize audio data transfer between client and server

## Priority 2: Audio Processing & Silero VAD Enhancement (IN PROGRESS)
- âœ… Fix audio blob handling and processing in frontend
- âœ… Implement retry mechanism for transcription failures
- âœ… Add proper MIME type handling for audio files
- ðŸ”² Integrate Silero VAD as enhancement to current audio analysis service
- ðŸ”² Maintain existing WebSocket infrastructure and session management
- ðŸ”² Implement performance monitoring to compare Silero vs RMS approaches
- ðŸ”² Add spectral analysis for better noise/speech differentiation
- ðŸ”² Implement frequency band filtering for human voice isolation

## Priority 3: Emotion Intelligence & Hawkins Tracking
- ðŸ”² Implement text-based emotion analysis using pre-trained model (DistilBERT)
- ðŸ”² Create Hawkins Energy Scale mapping (5-7 levels: Shame â†’ Anger â†’ Neutral â†’ Acceptance â†’ Peace)
- ðŸ”² Develop emotion trajectory tracking over conversation sessions
- ðŸ”² Add emotion visualization component in UI
- ðŸ”² Implement backend storage for emotion state tracking
- ðŸ”² Create API endpoints for emotion state retrieval and updates

## Priority 4: Mentor Selection System
- ðŸ”² Expand mentor profiles with deeper philosophical nuance
- ðŸ”² Implement emotion-based mentor selection logic
- ðŸ”² Create system prompts optimized for different emotional states
- ðŸ”² Build mentor switching mechanism based on Hawkins level
- ðŸ”² Design architecture for future expansion to 100+ mentors
- ðŸ”² Implement voice profile mapping for each mentor

## Priority 5: Ethical Advisor & Safeguards
- ðŸ”² Implement rule-based ethical filter using Council AI Constitution
- ðŸ”² Create validation middleware for all mentor responses
- ðŸ”² Add violation detection and response refinement
- ðŸ”² Build logging system for ethical interventions
- ðŸ”² Implement response sanitization for alignment with Stoic principles

## Priority 6: Memory & Session Persistence
- ðŸ”² Implement Supabase integration for authentication and storage
- ðŸ”² Create conversation history persistence
- ðŸ”² Implement simple journaling functionality
- ðŸ”² Add session summarization capabilities
- ðŸ”² Build quote and insight tracking system

## Priority 7: Feedback System (RLHF Foundation)
- ðŸ”² Implement user feedback collection mechanism
- ðŸ”² Create emotion delta tracking (before/after conversation)
- ðŸ”² Develop simple scoring system for mentor effectiveness
- ðŸ”² Build data collection framework for future RLHF
- ðŸ”² Implement basic analytics dashboard

## Technical Implementation Details

### Silero VAD Integration
1. **Implementation Approach**
   - Add Silero VAD as a module behind existing audio analysis layer
   - Maintain current WebSocket architecture and session management
   - Implement as an enhancement rather than replacement
   - Retain local VAD as fallback system

2. **Performance Considerations**
   - Implement singleton pattern for model loading
   - Add metrics for comparing detection accuracy and latency
   - Optimize for different network and device conditions
   - Consider gradual rollout with A/B testing

### Emotion Intelligence System
1. **Text-Based Emotion Analysis**
   - Implement using pre-trained DistilBERT model
   - Extract sentiment and emotion classifications from transcribed text
   - Map detected emotions to Hawkins Energy Scale
   - Store emotion state in session data

2. **Hawkins Scale Implementation**
   - Create 5-7 tiered system from negative to positive states
   - Implement tracking mechanism for emotional trajectory
   - Develop visualization component for emotional state
   - Enable filtering and retrieval of past emotional states

### Mentor Selection System
1. **Core Implementation**
   - Define emotional triggers for each mentor
   - Create mapping between emotional states and mentor selection
   - Implement prompts optimized for different emotional contexts
   - Build dynamic system prompt generation based on emotion

2. **Scalable Architecture**
   - Design for eventual expansion to 100+ mentors
   - Implement mentor registry and configuration system
   - Create modular prompt structure with emotional adaptivity
   - Develop testing framework for mentor effectiveness

### Ethical Advisor Implementation
1. **Rule-Based Filter**
   - Implement Council AI Constitution as validation system
   - Create pre-processing middleware for all responses
   - Develop violation detection and reporting
   - Implement refinement requests for non-compliant responses

2. **Integration Points**
   - Add as pre-response filter in API backend
   - Implement logging system for validation results
   - Create feedback loop for improvement
   - Build UI indicators for ethical alignments

## Testing Strategy
1. **VAD Testing**
   - Compare Silero vs current RMS system accuracy
   - Benchmark in different noise environments
   - Test with various accents and speech patterns
   - Measure false positive/negative rates

2. **Emotion Detection Testing**
   - Create test suite with diverse emotional inputs
   - Validate Hawkins mapping accuracy
   - Test emotion trajectory tracking
   - Assess mentor selection appropriateness

3. **Ethical Filter Testing**
   - Create tests for each constitutional rule
   - Validate violation detection
   - Test refinement quality
   - Measure impact on response latency

## Updated Timeline

### Phase 1: Core MVP (Weeks 1-4)
1. **Text-based Emotion Engine** (3-5 days)
   - ðŸ”² Implement text-based sentiment/emotion classifier
   - ðŸ”² Create Hawkins mapping (5-7 levels)

2. **Mentor Selector** (3-5 days)
   - ðŸ”² Map 3 personas to emotional states
   - ðŸ”² Implement selection logic

3. **Voice Pipeline Enhancement** (7-10 days)
   - ðŸ”² Integrate Silero VAD
   - ðŸ”² Enhance audio processing
   - ðŸ”² Connect emotion analysis

4. **Basic State Tracking** (5-7 days)
   - ðŸ”² Set up Supabase integration
   - ðŸ”² Implement session persistence
   - ðŸ”² Add basic quote logging

5. **Ethical Filter** (4-6 days)
   - ðŸ”² Implement Council AI Constitution
   - ðŸ”² Add response validation

### Phase 2: Growth Layer (Weeks 5-8)
1. **Journaling Timeline** (5-7 days)
   - ðŸ”² Create emotion replay visualization
   - ðŸ”² Implement journal entry system

2. **Memory Enhancement** (5-7 days)
   - ðŸ”² Add vector storage
   - ðŸ”² Implement session summarization

3. **Feedback System** (7-10 days)
   - ðŸ”² Build emotion delta tracking
   - ðŸ”² Implement feedback collection

4. **Mobile Optimization** (7-10 days)
   - ðŸ”² Create responsive design
   - ðŸ”² Optimize for offline mode

## Progress Tracking
We'll continue to use GitHub issues and project boards to track implementation progress, with weekly reviews to adjust priorities based on development velocity and user feedback.

**Last Updated: 2024-08-05**
